{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxVyAmN2OsdB"
      },
      "source": [
        "**Nama : Riki Ardi Pranata**\n",
        "\n",
        "**Nim : G.231.22.0118**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eliW-lv-Nvr7"
      },
      "source": [
        "**supervised learning**\n",
        "\n",
        "(bayesian_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lJuzBl5TLoE3"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "from scipy.stats import chi2, multivariate_normal\n",
        "from mlfromscratch.utils import mean_squared_error, train_test_split, polynomial_features\n",
        "\n",
        "\n",
        "\n",
        "class BayesianRegression(object):\n",
        "    \"\"\"Bayesian regression model. If poly_degree is specified the features will\n",
        "    be transformed to with a polynomial basis function, which allows for polynomial\n",
        "    regression. Assumes Normal prior and likelihood for the weights and scaled inverse\n",
        "    chi-squared prior and likelihood for the variance of the weights.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_draws: float\n",
        "        The number of simulated draws from the posterior of the parameters.\n",
        "    mu0: array\n",
        "        The mean values of the prior Normal distribution of the parameters.\n",
        "    omega0: array\n",
        "        The precision matrix of the prior Normal distribution of the parameters.\n",
        "    nu0: float\n",
        "        The degrees of freedom of the prior scaled inverse chi squared distribution.\n",
        "    sigma_sq0: float\n",
        "        The scale parameter of the prior scaled inverse chi squared distribution.\n",
        "    poly_degree: int\n",
        "        The polynomial degree that the features should be transformed to. Allows\n",
        "        for polynomial regression.\n",
        "    cred_int: float\n",
        "        The credible interval (ETI in this impl.). 95 => 95% credible interval of the posterior\n",
        "        of the parameters.\n",
        "\n",
        "    Reference:\n",
        "        https://github.com/mattiasvillani/BayesLearnCourse/raw/master/Slides/BayesLearnL5.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, n_draws, mu0, omega0, nu0, sigma_sq0, poly_degree=0, cred_int=95):\n",
        "        self.w = None\n",
        "        self.n_draws = n_draws\n",
        "        self.poly_degree = poly_degree\n",
        "        self.cred_int = cred_int\n",
        "\n",
        "        # Prior parameters\n",
        "        self.mu0 = mu0\n",
        "        self.omega0 = omega0\n",
        "        self.nu0 = nu0\n",
        "        self.sigma_sq0 = sigma_sq0\n",
        "\n",
        "    # Allows for simulation from the scaled inverse chi squared\n",
        "    # distribution. Assumes the variance is distributed according to\n",
        "    # this distribution.\n",
        "    # Reference:\n",
        "    #   https://en.wikipedia.org/wiki/Scaled_inverse_chi-squared_distribution\n",
        "    def _draw_scaled_inv_chi_sq(self, n, df, scale):\n",
        "        X = chi2.rvs(size=n, df=df)\n",
        "        sigma_sq = df * scale / X\n",
        "        return sigma_sq\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        # If polynomial transformation\n",
        "        if self.poly_degree:\n",
        "            X = polynomial_features(X, degree=self.poly_degree)\n",
        "\n",
        "        n_samples, n_features = np.shape(X)\n",
        "\n",
        "        X_X = X.T.dot(X)\n",
        "\n",
        "        # Least squares approximate of beta\n",
        "        beta_hat = np.linalg.pinv(X_X).dot(X.T).dot(y)\n",
        "\n",
        "        # The posterior parameters can be determined analytically since we assume\n",
        "        # conjugate priors for the likelihoods.\n",
        "\n",
        "        # Normal prior / likelihood => Normal posterior\n",
        "        mu_n = np.linalg.pinv(X_X + self.omega0).dot(X_X.dot(beta_hat)+self.omega0.dot(self.mu0))\n",
        "        omega_n = X_X + self.omega0\n",
        "        # Scaled inverse chi-squared prior / likelihood => Scaled inverse chi-squared posterior\n",
        "        nu_n = self.nu0 + n_samples\n",
        "        sigma_sq_n = (1.0/nu_n)*(self.nu0*self.sigma_sq0 + \\\n",
        "            (y.T.dot(y) + self.mu0.T.dot(self.omega0).dot(self.mu0) - mu_n.T.dot(omega_n.dot(mu_n))))\n",
        "\n",
        "        # Simulate parameter values for n_draws\n",
        "        beta_draws = np.empty((self.n_draws, n_features))\n",
        "        for i in range(self.n_draws):\n",
        "            sigma_sq = self._draw_scaled_inv_chi_sq(n=1, df=nu_n, scale=sigma_sq_n)\n",
        "            beta = multivariate_normal.rvs(size=1, mean=mu_n[:,0], cov=sigma_sq*np.linalg.pinv(omega_n))\n",
        "            # Save parameter draws\n",
        "            beta_draws[i, :] = beta\n",
        "\n",
        "        # Select the mean of the simulated variables as the ones used to make predictions\n",
        "        self.w = np.mean(beta_draws, axis=0)\n",
        "\n",
        "        # Lower and upper boundary of the credible interval\n",
        "        l_eti = 50 - self.cred_int/2\n",
        "        u_eti = 50 + self.cred_int/2\n",
        "        self.eti = np.array([[np.percentile(beta_draws[:,i], q=l_eti), np.percentile(beta_draws[:,i], q=u_eti)] \\\n",
        "                                for i in range(n_features)])\n",
        "\n",
        "    def predict(self, X, eti=False):\n",
        "\n",
        "        # If polynomial transformation\n",
        "        if self.poly_degree:\n",
        "            X = polynomial_features(X, degree=self.poly_degree)\n",
        "\n",
        "        y_pred = X.dot(self.w)\n",
        "        # If the lower and upper boundaries for the 95%\n",
        "        # equal tail interval should be returned\n",
        "        if eti:\n",
        "            lower_w = self.eti[:, 0]\n",
        "            upper_w = self.eti[:, 1]\n",
        "            y_lower_pred = X.dot(lower_w)\n",
        "            y_upper_pred = X.dot(upper_w)\n",
        "            return y_pred, y_lower_pred, y_upper_pred\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkdGqr2tN5-C"
      },
      "source": [
        "**unsupervised learning**\n",
        "\n",
        "(genetic algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7XaWi_BON5sn"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "class GeneticAlgorithm():\n",
        "    \"\"\"An implementation of a Genetic Algorithm which will try to produce the user\n",
        "    specified target string.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    target_string: string\n",
        "        The string which the GA should try to produce.\n",
        "    population_size: int\n",
        "        The number of individuals (possible solutions) in the population.\n",
        "    mutation_rate: float\n",
        "        The rate (or probability) of which the alleles (chars in this case) should be\n",
        "        randomly changed.\n",
        "    \"\"\"\n",
        "    def __init__(self, target_string, population_size, mutation_rate):\n",
        "        self.target = target_string\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.letters = [\" \"] + list(string.ascii_letters)\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\" Initialize population with random strings \"\"\"\n",
        "        self.population = []\n",
        "        for _ in range(self.population_size):\n",
        "            # Select random letters as new individual\n",
        "            individual = \"\".join(np.random.choice(self.letters, size=len(self.target)))\n",
        "            self.population.append(individual)\n",
        "\n",
        "    def _calculate_fitness(self):\n",
        "        \"\"\" Calculates the fitness of each individual in the population \"\"\"\n",
        "        population_fitness = []\n",
        "        for individual in self.population:\n",
        "            # Calculate loss as the alphabetical distance between\n",
        "            # the characters in the individual and the target string\n",
        "            loss = 0\n",
        "            for i in range(len(individual)):\n",
        "                letter_i1 = self.letters.index(individual[i])\n",
        "                letter_i2 = self.letters.index(self.target[i])\n",
        "                loss += abs(letter_i1 - letter_i2)\n",
        "            fitness = 1 / (loss + 1e-6)\n",
        "            population_fitness.append(fitness)\n",
        "        return population_fitness\n",
        "\n",
        "    def _mutate(self, individual):\n",
        "        \"\"\" Randomly change the individual's characters with probability\n",
        "        self.mutation_rate \"\"\"\n",
        "        individual = list(individual)\n",
        "        for j in range(len(individual)):\n",
        "            # Make change with probability mutation_rate\n",
        "            if np.random.random() < self.mutation_rate:\n",
        "                individual[j] = np.random.choice(self.letters)\n",
        "        # Return mutated individual as string\n",
        "        return \"\".join(individual)\n",
        "\n",
        "    def _crossover(self, parent1, parent2):\n",
        "        \"\"\" Create children from parents by crossover \"\"\"\n",
        "        # Select random crossover point\n",
        "        cross_i = np.random.randint(0, len(parent1))\n",
        "        child1 = parent1[:cross_i] + parent2[cross_i:]\n",
        "        child2 = parent2[:cross_i] + parent1[cross_i:]\n",
        "        return child1, child2\n",
        "\n",
        "    def run(self, iterations):\n",
        "        # Initialize new population\n",
        "        self._initialize()\n",
        "\n",
        "        for epoch in range(iterations):\n",
        "            population_fitness = self._calculate_fitness()\n",
        "\n",
        "            fittest_individual = self.population[np.argmax(population_fitness)]\n",
        "            highest_fitness = max(population_fitness)\n",
        "\n",
        "            # If we have found individual which matches the target => Done\n",
        "            if fittest_individual == self.target:\n",
        "                break\n",
        "\n",
        "            # Set the probability that the individual should be selected as a parent\n",
        "            # proportionate to the individual's fitness.\n",
        "            parent_probabilities = [fitness / sum(population_fitness) for fitness in population_fitness]\n",
        "\n",
        "            # Determine the next generation\n",
        "            new_population = []\n",
        "            for i in np.arange(0, self.population_size, 2):\n",
        "                # Select two parents randomly according to probabilities\n",
        "                parent1, parent2 = np.random.choice(self.population, size=2, p=parent_probabilities, replace=False)\n",
        "                # Perform crossover to produce offspring\n",
        "                child1, child2 = self._crossover(parent1, parent2)\n",
        "                # Save mutated offspring for next generation\n",
        "                new_population += [self._mutate(child1), self._mutate(child2)]\n",
        "\n",
        "            print (\"[%d Closest Candidate: '%s', Fitness: %.2f]\" % (epoch, fittest_individual, highest_fitness))\n",
        "            self.population = new_population\n",
        "\n",
        "        print (\"[%d Answer: '%s']\" % (epoch, fittest_individual))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOL5KEM6yIVGawYi89sroNP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
